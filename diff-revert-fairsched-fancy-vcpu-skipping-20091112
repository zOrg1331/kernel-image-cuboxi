diff --git a/include/linux/fairsched.h b/include/linux/fairsched.h
index dec7371..1f208fc 100644
--- a/include/linux/fairsched.h
+++ b/include/linux/fairsched.h
@@ -113,13 +113,6 @@ extern struct fairsched_node *fairsched_schedule(
 		struct fairsched_node *cur_node,
 		int cur_node_active,
 		cycles_t time);
-extern struct fairsched_node *fairsched_next(
-		struct fairsched_node *prev_node,
-		struct fairsched_node *cur_node,
-		int cur_node_active);
-extern void fairsched_switch(
-		struct fairsched_node *node,
-		cycles_t time);
 
 /*
  * Management functions.
diff --git a/kernel/fairsched.c b/kernel/fairsched.c
index 8cf7d1f..5d8923c 100644
--- a/kernel/fairsched.c
+++ b/kernel/fairsched.c
@@ -600,32 +600,15 @@ struct fairsched_node *fairsched_schedule(
 
 	list_for_each_entry(p, &fairsched_running_head, runlist) {
 		if (p->nr_pcpu < p->nr_ready ||
-		    (cur_node_active && p == cur_node))
-			return p;
-	}
-	return NULL;
-}
-
-struct fairsched_node *fairsched_next(
-		struct fairsched_node *p,
-		struct fairsched_node *cur_node,
-		int cur_node_active)
-{
-	list_for_each_entry_continue(p, &fairsched_running_head, runlist) {
-		if (p->nr_pcpu < p->nr_ready ||
-		    (cur_node_active && p == cur_node))
+		    (cur_node_active && p == cur_node)) {
+			if (p->rate_limited)
+				fairsched_ratelimit_charge_advance(p, time);
 			return p;
+		}
 	}
 	return NULL;
 }
 
-void fairsched_switch(
-		struct fairsched_node *node,
-		cycles_t time)
-{
-	if (node->rate_limited)
-		fairsched_ratelimit_charge_advance(node, time);
-}
 
 /*********************************************************************/
 /*
diff --git a/kernel/sched.c b/kernel/sched.c
index 0dc8659..9cb0e2c 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -369,7 +369,7 @@ unsigned int nr_runnable_vcpus = -1;
 
 u32 vcpu_sched_timeslice = 5;
 int vcpu_timeslice = 20;
-u32 vcpu_hot_timeslice = 10;	/* < 4 won't work for HZ=250 */
+u32 vcpu_hot_timeslice = 4;	/* < 4 won't work for HZ=250 */
 EXPORT_SYMBOL(vcpu_sched_timeslice);
 EXPORT_SYMBOL(vcpu_timeslice);
 EXPORT_SYMBOL(vcpu_hot_timeslice);
@@ -770,10 +770,9 @@ static int idle_balance(vcpu_t this_cpu, struct rq *this_rq);
 static vcpu_t schedule_vcpu(vcpu_t cur_vcpu, cycles_t cycles)
 {
 	struct vcpu_scheduler *vsched;
-	vcpu_t vcpu;
+	vcpu_t vcpu, best_vcpu;
 	unsigned long time;
 	struct rq *rq;
-	int pcpu = raw_smp_processor_id();
 #ifdef CONFIG_FAIRSCHED
 	struct fairsched_node *node, *nodec;
 
@@ -791,7 +790,6 @@ restart:
 	node = fairsched_schedule(node, nodec,
 			cur_vcpu->active,
 			cycles);
-again:
 	if (unlikely(node == NULL))
 		goto idle;
 
@@ -831,26 +829,22 @@ again:
 	 * for CPU longer than others. If all vcpu's are hot, use the oldest
 	 * one.
 	 */
+	best_vcpu = list_entry(vsched->active_list.next,
+						struct vcpu_struct, list);
 	list_for_each_entry(vcpu, &vsched->active_list, list) {
-		if (vcpu_last_pcpu(vcpu) == pcpu)
-			goto chosen;
-
-		if (cpu_isset(vcpu_last_pcpu(vcpu), idle_vsched.pcpu_running_map))
+		/* Skip hot VCPU's that were running on another CPU's */
+		if (vcpu->stop_time > time && 
+				vcpu_last_pcpu(vcpu) != raw_smp_processor_id())
 			continue;
 
-		if (time_after_eq(time, vcpu->stop_time))
-			goto chosen;
+		best_vcpu = vcpu;
+		break;
 	}
+	vcpu = best_vcpu;
 
-	node = fairsched_next(node, nodec,
-			cur_vcpu->active);
-	goto again;
-
-chosen:
 	/* add it to running list */
 	__vcpu_get(vcpu);
 done:
-	fairsched_switch(node, cycles);
 	spin_unlock(&fairsched_lock);
 
 	rq = vcpu_rq(vcpu);
