From: Don Dugger <ddugger@redhat.com>
Date: Thu, 5 Aug 2010 20:14:04 -0400
Subject: [xen] CPU synchronization during MTRR register update
Message-id: <201008052014.o75KE4Cs022519@sobek.n0ano.com>
Patchwork-id: 27428
O-Subject: [RHEL 5.6 PATCH V2] BZ 594546: xen: CPU synchronization while doing
	MTRR register update
Bugzilla: 594546
RH-Acked-by: Paolo Bonzini <pbonzini@redhat.com>
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>

(Version 2, RH kernel changed after I built the origianl version and
before I posted the patch.  Added an include of `mtrr.h' to silence
compiler warnings.)

The current Xen code does not synchronize all the cpus while
initializing MTRR registers when a cpu comes up.

As per IA32 SDM vol 3: Section: 10.11.8 MTRR Considerations in MP
Systems, all the processors should be synchronized while updating
MTRRs.

Processors starting with westmere are caching VMCS data for better VMX
performance. These processors also have Hyper-threading support. With
hyper-threading, when one thread's cache is disabled, it also disables
cache for the sibling threads. And MTRR register updating procedure
involves cache disabling. So if cpus are not synchronized, updating
MTRR registers on a thread results in the VMCS data from sibling
threads becoming inaccessible, potentially causing a system failure.

With this patch while updating the MTRR registers, all the cpus are
synchronized as per the IA32 SDM. Also at the boot time and resume
time when multiple cpus are brought up, an optimization is added to
delay the MTRR initialization until all the cpus are up, to avoid
synchronizing CPUs multiple times.

Signed-off-by: Nitin A Kamble <nitin.a.kamble@intel.com>
Signed-off-by: Suresh B Siddha <suresh.b.siddha@intel.com>
Signed-off-by: Asit K Mallick <asit.k.mallick@intel.com>

Upstream Status - CS 20021

Brew build - http://brewweb.devel.redhat.com/brew/taskinfo?taskID=2658514

Testing - Tested to not cause any booting problems on a Weybridge VT machine.

Signed-off-by: Don Dugger <donald.d.dugger!intel.com>
---
 arch/x86/cpu/common.c    |    2 -
 arch/x86/cpu/mtrr/main.c |   53 +++++++++++++++++++++++++++++++++++++--------
 arch/x86/smpboot.c       |    4 +++
 include/asm-x86/mtrr.h   |    4 +++
 4 files changed, 51 insertions(+), 12 deletions(-)

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/x86/cpu/common.c b/arch/x86/cpu/common.c
index 9490f59..9443448 100644
--- a/arch/x86/cpu/common.c
+++ b/arch/x86/cpu/common.c
@@ -440,8 +440,6 @@ void __devinit identify_cpu(struct cpuinfo_x86 *c)
 
 	if (c == &boot_cpu_data)
 		mtrr_bp_init();
-	else
-		mtrr_ap_init();
 }
 
 #ifdef CONFIG_X86_HT
diff --git a/arch/x86/cpu/mtrr/main.c b/arch/x86/cpu/mtrr/main.c
index a82caaa..e015bb7 100644
--- a/arch/x86/cpu/mtrr/main.c
+++ b/arch/x86/cpu/mtrr/main.c
@@ -134,6 +134,17 @@ struct set_mtrr_data {
 	mtrr_type	smp_type;
 };
 
+/* As per the IA32 SDM vol-3: 10.11.8 MTRR Considerations in MP Systems section
+ * MTRRs updates must to be synchronized across all the processors.
+ * This flags avoids multiple cpu synchronization while booting each cpu.
+ * At the boot & resume time, this flag is turned on in mtrr_aps_sync_begin().
+ * Using this flag the mtrr initialization (and the all cpus sync up) in the 
+ * mtrr_ap_init() is avoided while booting each cpu. 
+ * After all the cpus have came up, then mtrr_aps_sync_end() synchronizes all 
+ * the cpus and updates mtrrs on all of them. Then this flag is turned off.
+ */
+int hold_mtrr_updates_on_aps;
+
 #ifdef CONFIG_SMP
 
 static void ipi_handler(void *info)
@@ -151,11 +162,13 @@ static void ipi_handler(void *info)
 		cpu_relax();
 
 	/*  The master has cleared me to execute  */
-	if (data->smp_reg != ~0U) 
+	if (data->smp_reg == ~0U) /* update all mtrr registers */
+		/* At the cpu hot-add time this will reinitialize mtrr 
+ 		 * registres on the existing cpus. It is ok.  */
+		mtrr_if->set_all();
+	else /* single mtrr register update */
 		mtrr_if->set(data->smp_reg, data->smp_base, 
 			     data->smp_size, data->smp_type);
-	else
-		mtrr_if->set_all();
 
 	atomic_dec(&data->count);
 	while(atomic_read(&data->gate))
@@ -240,7 +253,11 @@ static void set_mtrr(unsigned int reg, unsigned long base,
 	 * to replicate across all the APs. 
 	 * If we're doing that @reg is set to something special...
 	 */
-	if (reg != ~0U) 
+	if (reg == ~0U)  /* update all mtrr registers */
+		/* at boot or resume time, this will reinitialize the mtrrs on 
+		 * the bp. It is ok. */
+		mtrr_if->set_all();
+	else /* update the single mtrr register */
 		mtrr_if->set(reg,base,size,type);
 
 	/* wait for the others */
@@ -639,9 +656,7 @@ void __init mtrr_bp_init(void)
 
 void mtrr_ap_init(void)
 {
-	unsigned long flags;
-
-	if (!mtrr_if || !use_intel())
+	if (!mtrr_if || !use_intel() || hold_mtrr_updates_on_aps)
 		return;
 	/*
 	 * Ideally we should hold mtrr_sem here to avoid mtrr entries changed,
@@ -651,11 +666,29 @@ void mtrr_ap_init(void)
 	 * 2.cpu hotadd time. We let mtrr_add/del_page hold cpuhotplug lock to
 	 * prevent mtrr entry changes
 	 */
-	local_irq_save(flags);
+	set_mtrr(~0U, 0, 0, 0);
+}
 
-	mtrr_if->set_all();
+void mtrr_aps_sync_begin(void)
+{
+	if (!use_intel())
+		return;
+	hold_mtrr_updates_on_aps = 1;
+}
 
-	local_irq_restore(flags);
+void mtrr_aps_sync_end(void)
+{
+	if (!use_intel())
+		return;
+	set_mtrr(~0U, 0, 0, 0);
+	hold_mtrr_updates_on_aps = 0;
+}
+
+void mtrr_bp_restore(void)
+{
+	if (!use_intel())
+		return;
+	mtrr_if->set_all();
 }
 
 static int __init mtrr_init_finialize(void)
diff --git a/arch/x86/smpboot.c b/arch/x86/smpboot.c
index c23c90b..e774b8c 100644
--- a/arch/x86/smpboot.c
+++ b/arch/x86/smpboot.c
@@ -50,6 +50,7 @@
 #include <asm/div64.h>
 #include <asm/flushtlb.h>
 #include <asm/msr.h>
+#include <asm/mtrr.h>
 #include <mach_apic.h>
 #include <mach_wakecpu.h>
 #include <smpboot_hooks.h>
@@ -534,6 +535,7 @@ void __devinit start_secondary(void *unused)
 
 	/* We can take interrupts now: we're officially "up". */
 	local_irq_enable();
+	mtrr_ap_init();
 
         init_percpu_time();
 
@@ -1129,6 +1131,7 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 	cpu_callin_map = cpumask_of_cpu(0);
 	mb();
 	smp_boot_cpus(max_cpus);
+	mtrr_aps_sync_begin();
 }
 
 void __devinit smp_prepare_boot_cpu(void)
@@ -1165,6 +1168,7 @@ void __init smp_cpus_done(unsigned int max_cpus)
 #ifdef CONFIG_X86_IO_APIC
 	setup_ioapic_dest();
 #endif
+	mtrr_aps_sync_end();
 #ifndef CONFIG_HOTPLUG_CPU
 	/*
 	 * Disable executability of the SMP trampoline:
diff --git a/include/asm-x86/mtrr.h b/include/asm-x86/mtrr.h
index 8f61580..fe975a4 100644
--- a/include/asm-x86/mtrr.h
+++ b/include/asm-x86/mtrr.h
@@ -18,5 +18,9 @@ extern int mtrr_add_page(unsigned long base, unsigned long size,
 extern int mtrr_del(int reg, unsigned long base, unsigned long size);
 extern int mtrr_del_page(int reg, unsigned long base, unsigned long size);
 extern void mtrr_centaur_report_mcr(int mcr, u32 lo, u32 hi);
+extern int hold_mtrr_updates_on_aps;
+extern void mtrr_aps_sync_begin(void);
+extern void mtrr_aps_sync_end(void);
+extern void mtrr_bp_restore(void);
 
 #endif /* __ASM_X86_MTRR_H__ */
