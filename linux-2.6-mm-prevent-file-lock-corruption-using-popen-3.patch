From: Larry Woodman <lwoodman@redhat.com>
Date: Thu, 23 Dec 2010 05:50:32 -0500
Subject: [mm] prevent file lock corruption using popen(3)
Message-id: <4D12E328.8060006@redhat.com>
Patchwork-id: 30924
O-Subject: [RHEL5.6 Patch] Prevent file lock corruption using popen(3)
Bugzilla: 664931
RH-Acked-by: Rik van Riel <riel@redhat.com>
RH-Acked-by: Johannes Weiner <jweiner@redhat.com>

popen(3) creates a child process and both parent and child write fp->pid causing
do_wp_page() race.

Fixed by upstream commit 945754a1754f9d4c2974a8241ad4f92fad7f3a6a <http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=945754a1754f9d4c2974a8241ad4f92fad7f3a6a>
that is missing from RHEL5.

--------------------------------------------------------------------------------
author	Nick Piggin <npiggin@suse.de>
	Mon, 23 Jun 2008 12:30:30 +0000 (14:30 +0200)
committer	Linus Torvalds <torvalds@linux-foundation.org>
	Mon, 23 Jun 2008 18:28:32 +0000 (11:28 -0700)
There is a race in the COW logic.  It contains a shortcut to avoid the
COW and reuse the page if we have the sole reference on the page,
however it is possible to have two racing do_wp_page()ers with one
causing the other to mistakenly believe it is safe to take the shortcut
when it is not.  This could lead to data corruption.

Process 1 and process2 each have a wp pte of the same anon page (ie.
one forked the other).  The page's mapcount is 2.  Then they both
attempt to write to it around the same time...

  proc1 proc2 thr1 proc2 thr2
  CPU0 CPU1 CPU3
  do_wp_page() do_wp_page()
 trylock_page()
  can_share_swap_page()
   load page mapcount (==2)
  reuse = 0
 pte unlock
 copy page to new_page
 pte lock
 page_remove_rmap(page);
   trylock_page()
    can_share_swap_page()
     load page mapcount (==1)
    reuse = 1
   ptep_set_access_flags (allow W)

  write private key into page
read from page
ptep_clear_flush()
set_pte_at(pte of new_page)

Fix this by moving the page_remove_rmap of the old page after the pte
clear and flush.  Potentially the entire branch could be moved down
here, but in order to stay consistent, I won't (should probably move all
the *_mm_counter stuff with one patch).

Signed-off-by: Nick Piggin <npiggin@suse.de>
Acked-by: Hugh Dickins <hugh@veritas.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

------------------------------------------------------------------------

The attached upstream backport fixes this problem & BZ 664931

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/mm/memory.c b/mm/memory.c
index 4d6a646..0798204 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -1859,7 +1859,6 @@ gotten:
 	page_table = pte_offset_map_lock(mm, pmd, address, &ptl);
 	if (likely(pte_same(*page_table, orig_pte))) {
 		if (old_page) {
-			page_remove_rmap(old_page);
 			if (!PageAnon(old_page)) {
 				dec_mm_counter(mm, file_rss);
 				inc_mm_counter(mm, anon_rss);
@@ -1885,6 +1884,31 @@ gotten:
 		update_mmu_cache(vma, address, entry);
 		lru_cache_add_active(new_page);
 		page_add_new_anon_rmap(new_page, vma, address);
+		if (old_page) {
+			/*
+			 * Only after switching the pte to the new page may
+			 * we remove the mapcount here. Otherwise another
+			 * process may come and find the rmap count decremented
+			 * before the pte is switched to the new page, and
+			 * "reuse" the old page writing into it while our pte
+			 * here still points into it and can be read by other
+			 * threads.
+			 *
+			 * The critical issue is to order this
+			 * page_remove_rmap with the ptp_clear_flush above.
+			 * Those stores are ordered by (if nothing else,)
+			 * the barrier present in the atomic_add_negative
+			 * in page_remove_rmap.
+			 *
+			 * Then the TLB flush in ptep_clear_flush ensures that
+			 * no process can access the old page before the
+			 * decremented mapcount is visible. And the old page
+			 * cannot be reused until after the decremented
+			 * mapcount is visible. So transitively, TLBs to
+			 * old page will be flushed before it can be reused.
+			 */
+			page_remove_rmap(old_page);
+		}
 
 		/* Free the old page.. */
 		new_page = old_page;
