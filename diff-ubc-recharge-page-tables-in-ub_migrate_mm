Subject: [PATCH rh5 1/3] ubc: recharge page tables in ub_migrate_mm
From: Konstantin Khlebnikov <khlebnikov@parallels.com>
Date: Wed, 9 Feb 2011 14:05:32 +0300
To: "vzlin-dev@sw.ru" <vzlin-dev@sw.ru>
CC: Pavel Emelianov <xemul@parallels.com>

Recharge page tables at mm migration into/between sub-beancointers.

https://jira.sw.ru/browse/PSBM-6788

Signed-off-by: Konstantin Khlebnikov <khlebnikov@openvz.org>
---
 include/linux/sched.h  |    1 +
 kernel/fork.c          |    3 +++
 kernel/ub/ub_mem.c     |    2 ++
 kernel/ub/ub_page_bc.c |    6 ++++++
 4 files changed, 12 insertions(+), 0 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 262bdd2..e36e7de 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -451,6 +451,7 @@ struct mm_struct {
 #endif
 	/* protected by mmap_sem write held or read with page_table_lock */
 	long page_table_acct;
+	long page_table_charged;
 };
 
 static inline unsigned long get_mm_hiwater_rss(struct mm_struct *mm)
diff --git a/kernel/fork.c b/kernel/fork.c
index 4d9817d..afafc3b 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -507,6 +507,8 @@ static struct mm_struct * mm_init(struct mm_struct * mm,
 	INIT_LIST_HEAD(&mm->mmlist);
 	mm->core_waiters = 0;
 	mm->nr_ptes = 0;
+	mm->page_table_acct = 0;
+	mm->page_table_charged = 0;
 	set_mm_counter(mm, file_rss, 0);
 	set_mm_counter(mm, anon_rss, 0);
 	spin_lock_init(&mm->page_table_lock);
@@ -563,6 +565,7 @@ void fastcall __mmdrop(struct mm_struct *mm)
 	free_mm_flags(mm);
 	mm_free_pgd(mm);
 	BUG_ON(mm->page_table_acct);
+	BUG_ON(mm->page_table_charged);
 	destroy_context(mm);
 	mmu_notifier_mm_destroy(mm);
 	put_mm_ub(mm);
diff --git a/kernel/ub/ub_mem.c b/kernel/ub/ub_mem.c
index 0554a05..57a6162 100644
--- a/kernel/ub/ub_mem.c
+++ b/kernel/ub/ub_mem.c
@@ -444,6 +444,7 @@ int ub_commit_page_tables(struct mm_struct *mm, int locked)
 		spin_lock(&mm->page_table_lock);
 	acct = mm->page_table_acct;
 	mm->page_table_acct = 0;
+	mm->page_table_charged += acct;
 	if (!locked)
 		spin_unlock(&mm->page_table_lock);
 
@@ -455,6 +456,7 @@ int ub_commit_page_tables(struct mm_struct *mm, int locked)
 		if (!locked)
 			spin_lock(&mm->page_table_lock);
 		mm->page_table_acct += acct;
+		mm->page_table_charged -= acct;
 		if (!locked)
 			spin_unlock(&mm->page_table_lock);
 
diff --git a/kernel/ub/ub_page_bc.c b/kernel/ub/ub_page_bc.c
index f709f92..1238a43 100644
--- a/kernel/ub/ub_page_bc.c
+++ b/kernel/ub/ub_page_bc.c
@@ -713,6 +713,7 @@ void ub_migrate_mm(struct mm_struct *mm, struct user_beancounter *new_ub)
 {
 	struct user_beancounter *old_ub = mm->mm_ub;
 	struct vm_area_struct *vma;
+	unsigned long size;
 
 	/* implemented only migration into sub-beancounter */
 	BUG_ON(new_ub->parent != top_beancounter(old_ub));
@@ -747,6 +748,11 @@ void ub_migrate_mm(struct mm_struct *mm, struct user_beancounter *new_ub)
 				old_ub, new_ub);
 	}
 
+	size = mm->page_table_charged << PAGE_SHIFT;
+
+	uncharge_beancounter_notop(old_ub, UB_KMEMSIZE, size);
+	charge_beancounter_notop(new_ub, UB_KMEMSIZE, size);
+
 	mm->mm_ub = get_beancounter(new_ub);
 	put_beancounter(old_ub);
 

