From: Eric Sandeen <sandeen@redhat.com>
Date: Wed, 25 Mar 2009 15:42:37 -0500
Subject: [fs] block_page_mkwrite helper
Message-id: 49CA973D.9020009@redhat.com
O-Subject: [PATCH 2/10] block_page_mkwrite helper
Bugzilla: 470845
RH-Acked-by: Steven Whitehouse <swhiteho@redhat.com>
RH-Acked-by: Josef Bacik <josef@redhat.com>

Backport of:

commit 5417169026c3df151adf5a65eb061278b0a72e69
Author: David Chinner <dgc@sgi.com>
Date:   Thu Jul 19 17:39:55 2007 +1000

    [FS] Implement block_page_mkwrite.

    Many filesystems need a ->page-mkwrite callout to correctly
    set up pages that have been written to by mmap. This is especially
    important when mmap is writing into holes as it allows filesystems
    to correctly account for and allocate space before the mmap
    write is allowed to proceed.

    Protection against truncate races is provided by locking the page
    and checking to see whether the page mapping is correct and whether
    it is beyond EOF so we don't end up allowing allocations beyond
    the current EOF or changing EOF as a result of a mmap write.

    SGI-PV: 940392
    SGI-Modid: 2.6.x-xfs-melb:linux:29146a

    Signed-off-by: David Chinner <dgc@sgi.com>
    Signed-off-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Tim Shimmin <tes@sgi.com>

diff --git a/fs/buffer.c b/fs/buffer.c
index 0ba5cce..7dc34b0 100644
--- a/fs/buffer.c
+++ b/fs/buffer.c
@@ -2576,6 +2576,53 @@ int block_commit_write(struct page *page, unsigned from, unsigned to)
 	return 0;
 }
 
+/*
+ * block_page_mkwrite() is not allowed to change the file size as it gets
+ * called from a page fault handler when a page is first dirtied. Hence we must
+ * be careful to check for EOF conditions here. We set the page up correctly
+ * for a written page which means we get ENOSPC checking when writing into
+ * holes and correct delalloc and unwritten extent mapping on filesystems that
+ * support these features.
+ *
+ * We are not allowed to take the i_mutex here so we have to play games to
+ * protect against truncate races as the page could now be beyond EOF.  Because
+ * vmtruncate() writes the inode size before removing pages, once we have the
+ * page lock we can determine safely if the page is beyond EOF. If it is not
+ * beyond EOF, then the page is guaranteed safe against truncation until we
+ * unlock the page.
+ */
+int
+block_page_mkwrite(struct vm_area_struct *vma, struct page *page,
+		   get_block_t get_block)
+{
+	struct inode *inode = vma->vm_file->f_dentry->d_inode;
+	unsigned long end;
+	loff_t size;
+	int ret = -EINVAL;
+
+	lock_page(page);
+	size = i_size_read(inode);
+	if ((page->mapping != inode->i_mapping) ||
+	    (page_offset(page) > size)) {
+		/* page got truncated out from underneath us */
+		goto out_unlock;
+	}
+
+	/* page is wholly or partially inside EOF */
+	if (((page->index + 1) << PAGE_CACHE_SHIFT) > size)
+		end = size & ~PAGE_CACHE_MASK;
+	else
+		end = PAGE_CACHE_SIZE;
+
+	ret = block_prepare_write(page, 0, end, get_block);
+	if (!ret)
+		ret = block_commit_write(page, 0, end);
+
+out_unlock:
+	unlock_page(page);
+	return ret;
+}
+
 int generic_commit_write(struct file *file, struct page *page,
 		unsigned from, unsigned to)
 {
@@ -3455,6 +3502,7 @@ EXPORT_SYMBOL(__brelse);
 EXPORT_SYMBOL(__wait_on_buffer);
 EXPORT_SYMBOL(block_commit_write);
 EXPORT_SYMBOL(block_prepare_write);
+EXPORT_SYMBOL(block_page_mkwrite);
 EXPORT_SYMBOL(block_read_full_page);
 EXPORT_SYMBOL(block_sync_page);
 EXPORT_SYMBOL(block_truncate_page);
diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h
index 2d15847..0735044 100644
--- a/include/linux/buffer_head.h
+++ b/include/linux/buffer_head.h
@@ -220,6 +220,8 @@ int cont_write_begin(struct file *, struct address_space *, loff_t,
 int generic_cont_expand(struct inode *inode, loff_t size);
 int generic_cont_expand_simple(struct inode *inode, loff_t size);
 int block_commit_write(struct page *page, unsigned from, unsigned to);
+int block_page_mkwrite(struct vm_area_struct *vma, struct page *page,
+				get_block_t get_block);
 void block_sync_page(struct page *);
 void flush_inode_pages (struct inode * inode);
 sector_t generic_block_bmap(struct address_space *, sector_t, get_block_t *);
