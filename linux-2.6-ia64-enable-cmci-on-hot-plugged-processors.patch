From: Fabio Olive Leite <fleite@redhat.com>
Date: Mon, 21 Jan 2008 20:50:28 -0200
Subject: [ia64] enable CMCI on hot-plugged processors
Message-id: 20080121225027.GB3982@sleipnir.redhat.com
O-Subject: [PATCH RHEL5.2] [IA64] bz #426793: Enable CMCI on hot-plugged processors
Bugzilla: 426793

Hi all,

Sorry this is posted rather late. It kinda slipped through the cracks.

This patch is upstream, was verified by partner Fujitsu with a test
kernel based on 2.6.18-53.1.4.el5 and still applies and builds cleanly
on 2.6.18-71.el5. The exception is being reviewed, and there is a
strong business case behind it.

The code in the patch registers a cpu hot-plug event callback that
adjusts the CMCI mask of the new processors. I'm leaving the upstream
commit information untouched for the reference. Please ACK.

commit ed5d4026ae6f51bec25e03a891a7d59c492577ab
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Wed Dec 19 11:42:02 2007 -0800

    [IA64] Adjust CMCI mask on CPU hotplug

    Currently CMCI mask of hot-added CPU is always disabled after CPU hotplug.
    We should adjust this mask depending on CMC polling state.

    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: Satoru Takeuchi <takeuchi_satoru@jp.fujitsu.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/mca.c b/arch/ia64/kernel/mca.c
index 6c30bc1..e0bcc7f 100644
--- a/arch/ia64/kernel/mca.c
+++ b/arch/ia64/kernel/mca.c
@@ -72,6 +72,7 @@
 #include <linux/smp.h>
 #include <linux/workqueue.h>
 #include <linux/cpumask.h>
+#include <linux/cpu.h>
 
 #include <asm/delay.h>
 #include <asm/kdebug.h>
@@ -1771,6 +1772,36 @@ ia64_mca_cpu_init(void *cpu_data)
 							      PAGE_KERNEL));
 }
 
+static void __cpuinit ia64_mca_cmc_vector_adjust(void *dummy)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	if (!cmc_polling_enabled)
+		ia64_mca_cmc_vector_enable(NULL);
+	local_irq_restore(flags);
+}
+
+static int __cpuinit mca_cpu_callback(struct notifier_block *nfb,
+				      unsigned long action,
+				      void *hcpu)
+{
+	int hotcpu = (unsigned long) hcpu;
+
+	switch (action) {
+	case CPU_ONLINE:
+	case CPU_ONLINE_FROZEN:
+		smp_call_function_single(hotcpu, ia64_mca_cmc_vector_adjust,
+					 NULL, 1, 0);
+		break;
+	}
+	return NOTIFY_OK;
+}
+
+static struct notifier_block mca_cpu_notifier __cpuinitdata = {
+	.notifier_call = mca_cpu_callback
+};
+
 /*
  * ia64_mca_init
  *
@@ -1954,6 +1985,8 @@ ia64_mca_late_init(void)
 	if (!mca_init)
 		return 0;
 
+	register_hotcpu_notifier(&mca_cpu_notifier);
+
 	/* Setup the CMCI/P vector and handler */
 	init_timer(&cmc_poll_timer);
 	cmc_poll_timer.function = ia64_mca_cmc_poll;
