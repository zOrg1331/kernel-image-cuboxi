From: Jiri Pirko <jpirko@redhat.com>
Date: Wed, 24 Nov 2010 19:42:33 +0100
Subject: [net] fix deadlock in sock_queue_rcv_skb
Message-id: <20101124194232.GG4372@psychotron.redhat.com>
Patchwork-id: 29607
O-Subject: [RHEL5.5.z patch] BZ652536 net: fix deadlock in sock_queue_rcv_skb
Bugzilla: 652536
RH-Acked-by: David Miller <davem@redhat.com>
RH-Acked-by: Xiaotian Feng <dfeng@redhat.com>
RH-Acked-by: Thomas Graf <tgraf@redhat.com>

BZ652536
https://bugzilla.redhat.com/show_bug.cgi?id=652536

Description:
This is simple backport of the original 5.6 patch. CCing original ackers

---------------------------------------- original desc ----------------------------------------

Description:
There's a deadlock issue in udp_queue_rcv_skb, which is found
when we're trying to reproduce a rhel5 info leak CVE.

   udp_queue_rcv_skb
         |_ bh_lock_sock(sk)
         |_ __udp_queue_rcv_skb
            |_ sock_queue_rcv_skb
               |_ sk_filter(sk, skb, 1) ->  1 means needlock
                  |_ bh_lock_sock(sk) -> deadlock

This is a regression introduced by rhel5 commit 6865201191, the upstream is okay because sk_filter was adopted to rcu protection, but rhel5 hasn't taken
the sk_filter changes, so after we take commit 6865201191 in, we have a deadlock.

Eugene has opened this as  CVE-2010-4161

Upstream status:
upstream has changed to use rcu to protect sk_filter, but rhel5 can not use it because the kabi breakage.

Follow Neil's suggestion, move the contents of skb_queue_rcv_skb to an internal function that takes an extra
needlock argument, make skb_queue_rcv_skb call that internal function with
needlock set to 0, and create a new function skb_queue_rcv_skb_nolock which
calls it with needlock set to zero.

I also check all users of sock_queue_rcv_skb, and changes to skb_queue_rcv_skb_nolock if the user is not lock
free.

----------------------------------------------------------------------------------------------

Signed-off-by: Jiri Pirko <jpirko@redhat.com>

diff --git a/include/net/sock.h b/include/net/sock.h
index f539b08..af2d541 100644
--- a/include/net/sock.h
+++ b/include/net/sock.h
@@ -1282,6 +1282,7 @@ extern void sk_reset_timer(struct sock *sk, struct timer_list* timer,
 extern void sk_stop_timer(struct sock *sk, struct timer_list* timer);
 
 extern int sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb);
+extern int sock_queue_rcv_skb_nolock(struct sock *sk, struct sk_buff *skb);
 
 static inline int sock_queue_err_skb(struct sock *sk, struct sk_buff *skb)
 {
diff --git a/net/bluetooth/l2cap.c b/net/bluetooth/l2cap.c
index 89b63f9..7b9f167 100644
--- a/net/bluetooth/l2cap.c
+++ b/net/bluetooth/l2cap.c
@@ -1825,7 +1825,7 @@ static inline int l2cap_data_channel(struct l2cap_conn *conn, u16 cid, struct sk
 	 * But we don't have any other choice. L2CAP doesn't
 	 * provide flow control mechanism. */
 
-	if (!sock_queue_rcv_skb(sk, skb))
+	if (!sock_queue_rcv_skb_nolock(sk, skb))
 		goto done;
 
 drop:
@@ -1854,7 +1854,7 @@ static inline int l2cap_conless_channel(struct l2cap_conn *conn, u16 psm, struct
 	if (l2cap_pi(sk)->imtu < skb->len)
 		goto drop;
 
-	if (!sock_queue_rcv_skb(sk, skb))
+	if (!sock_queue_rcv_skb_nolock(sk, skb))
 		goto done;
 
 drop:
diff --git a/net/core/sock.c b/net/core/sock.c
index 620eaba..7411c3a 100644
--- a/net/core/sock.c
+++ b/net/core/sock.c
@@ -245,8 +245,7 @@ static void sock_disable_timestamp(struct sock *sk)
 	}
 }
 
-
-int sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
+static int __sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb, int needlock)
 {
 	int err = 0;
 	int skb_len;
@@ -260,11 +259,7 @@ int sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
 		goto out;
 	}
 
-	/* It would be deadlock, if sock_queue_rcv_skb is used
-	   with socket lock! We assume that users of this
-	   function are lock free.
-	*/
-	err = sk_filter(sk, skb, 1);
+	err = sk_filter(sk, skb, needlock);
 	if (err)
 		goto out;
 
@@ -290,6 +285,24 @@ int sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
 out:
 	return err;
 }
+
+/*
+ * sock_queue_rcv_skb_nolock should be used with socket lock
+ */
+int sock_queue_rcv_skb_nolock(struct sock *sk, struct sk_buff *skb)
+{
+	return __sock_queue_rcv_skb(sk, skb, 0);
+}
+EXPORT_SYMBOL(sock_queue_rcv_skb_nolock);
+
+/* It would be deadlock, if sock_queue_rcv_skb is used
+ * with socket lock! We assume that users of this
+ * function are lock free.
+ */
+int sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
+{
+	return __sock_queue_rcv_skb(sk, skb, 1);
+}
 EXPORT_SYMBOL(sock_queue_rcv_skb);
 
 int sk_receive_skb(struct sock *sk, struct sk_buff *skb)
diff --git a/net/ipv4/udp.c b/net/ipv4/udp.c
index d9f6108..0adee39 100644
--- a/net/ipv4/udp.c
+++ b/net/ipv4/udp.c
@@ -1014,7 +1014,7 @@ static int __udp_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
 {
 	int rc;
 
-	if ((rc = sock_queue_rcv_skb(sk, skb)) < 0) {
+	if ((rc = sock_queue_rcv_skb_nolock(sk, skb)) < 0) {
 		/* Note that an ENOMEM error is charged twice */
 		if (rc == -ENOMEM)
 			UDP_INC_STATS_BH(UDP_MIB_INERRORS);
diff --git a/net/ipv6/udp.c b/net/ipv6/udp.c
index 36d0301..41f7f00 100644
--- a/net/ipv6/udp.c
+++ b/net/ipv6/udp.c
@@ -382,7 +382,7 @@ static inline int udpv6_queue_rcv_skb(struct sock * sk, struct sk_buff *skb)
 		return 0;
 	}
 
-	if (sock_queue_rcv_skb(sk,skb)<0) {
+	if (sock_queue_rcv_skb_nolock(sk,skb)<0) {
 		UDP6_INC_STATS_BH(UDP_MIB_INERRORS);
 		kfree_skb(skb);
 		return 0;
diff --git a/net/llc/llc_conn.c b/net/llc/llc_conn.c
index c761c15..dd3684e 100644
--- a/net/llc/llc_conn.c
+++ b/net/llc/llc_conn.c
@@ -94,7 +94,7 @@ int llc_conn_state_process(struct sock *sk, struct sk_buff *skb)
 	switch (ev->ind_prim) {
 	case LLC_DATA_PRIM:
 		llc_save_primitive(sk, skb, LLC_DATA_PRIM);
-		if (unlikely(sock_queue_rcv_skb(sk, skb))) {
+		if (unlikely(sock_queue_rcv_skb_nolock(sk, skb))) {
 			/*
 			 * shouldn't happen
 			 */
